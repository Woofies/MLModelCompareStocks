{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwd741JCEE38",
        "outputId": "624cadf6-92dc-4006-b3bf-046a3fdc1964"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PySpark\n",
            "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from PySpark) (0.10.9.7)\n",
            "Building wheels for collected packages: PySpark\n",
            "  Building wheel for PySpark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PySpark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285397 sha256=38b13451987a35131a51bb0f58a5463e5ffd706f85f9b3c45d5fc75ae4f0e11a\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n",
            "Successfully built PySpark\n",
            "Installing collected packages: PySpark\n",
            "Successfully installed PySpark-3.4.1\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.10/dist-packages (0.2.25)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.5.3)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.22.4)\n",
            "Requirement already satisfied: requests>=2.26 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.27.1)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.9.3)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2022.7.1)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.3.8)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.11.2)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.4.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26->yfinance) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26->yfinance) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26->yfinance) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26->yfinance) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install PySpark\n",
        "!pip install yfinance"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from pyspark import SparkContext\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "\n",
        "class SVMRegression:\n",
        "\n",
        "    def __init__(self, learning_rate=1e-5, lambda_param=1e-5, n_iters=1000):\n",
        "        self.lr = learning_rate\n",
        "        self.lambda_param = lambda_param\n",
        "        self.n_iters = n_iters\n",
        "        self.w = None\n",
        "        self.b = None\n",
        "\n",
        "    def fit(self, X, y, sc=None):\n",
        "        # Create a SparkContext\n",
        "        if sc is None:\n",
        "          sc = SparkContext(appName=\"SVMRegressionMapReduce\")\n",
        "\n",
        "        # Broadcast the variables to all nodes for read-only access\n",
        "        lr_broadcast = sc.broadcast(self.lr)\n",
        "        lambda_param_broadcast = sc.broadcast(self.lambda_param)\n",
        "\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        # Initialize weights\n",
        "        self.w = np.zeros(n_features)\n",
        "        self.b = 0\n",
        "\n",
        "        # Convert X and y to RDDs\n",
        "        X_rdd = sc.parallelize(X.tolist())\n",
        "        y_rdd = sc.parallelize(y.tolist())\n",
        "\n",
        "        for _ in range(self.n_iters):\n",
        "          # Perform the distributed gradient updates using MapReduce\n",
        "          updates = X_rdd.zip(y_rdd).map(lambda x_y: self._gradient_update(x_y, lr_broadcast.value, lambda_param_broadcast.value))\n",
        "          # Aggregate the updates using reduce\n",
        "          total_update = updates.reduce(lambda acc, update: (acc[0] + update[0], acc[1] + update[1]))\n",
        "          # Apply the aggregated updates to the weights and bias\n",
        "          self.w -= total_update[0]\n",
        "          self.b -= total_update[1]\n",
        "\n",
        "        # Stop the SparkContext\n",
        "        sc.stop()\n",
        "\n",
        "    def _gradient_update(self, x_y, lr, lambda_param):\n",
        "        x_i = np.array(x_y[0])\n",
        "        y_i = x_y[1]\n",
        "        prediction = np.dot(x_i, self.w) - self.b\n",
        "        error = y_i - prediction\n",
        "\n",
        "        # Calculate the gradient update for weights and bias\n",
        "        w_update = lr * (2 * lambda_param * self.w - np.dot(x_i, error))\n",
        "        b_update = lr * (-2 * lambda_param * self.b + error)\n",
        "\n",
        "        return (w_update, b_update)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.dot(X, self.w) - self.b\n",
        "\n",
        "def load_dataset():\n",
        "  # Replace the stock symbol for respective ticker interested in comparing\n",
        "  stock_symbol = 'AAPL' # AAPL AMZN NVDA CNRG TAN BTC AMD INTC\n",
        "  df = yf.download(tickers=stock_symbol, period = '5y', interval = '1d') # Get data for the last 5 years w/ interval set to 1 day for all cases\n",
        "  type(df)\n",
        "\n",
        "  # Train/Test\n",
        "  data_training=pd.DataFrame(df['Close'][0:int(len(df)*0.70)])\n",
        "  data_testing=pd.DataFrame(df['Close'][int(len(df)*0.70):int(len(df))])\n",
        "\n",
        "  scaler=MinMaxScaler(feature_range=(0,1))\n",
        "\n",
        "  data_training_array=scaler.fit_transform(data_training)\n",
        "  data_training_array\n",
        "  data_training_array.shape\n",
        "\n",
        "  X_train=[]\n",
        "  y_train=[]\n",
        "\n",
        "  for i in range(100, data_training_array.shape[0]):\n",
        "    X_train.append(data_training_array[i-100:i])\n",
        "    y_train.append(data_training_array[i, 0])\n",
        "  X_train, y_train=np.array(X_train), np.array(y_train)\n",
        "\n",
        "  X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "\n",
        "  data_testing_array=scaler.fit_transform(data_testing)\n",
        "  data_testing_array\n",
        "\n",
        "  data_testing_array.shape\n",
        "\n",
        "  X_test=[]\n",
        "  y_test=[]\n",
        "\n",
        "  for i in range(100, data_testing_array.shape[0]):\n",
        "    X_test.append(data_testing_array[i-100:i])\n",
        "    y_test.append(data_testing_array[i, 0])\n",
        "  X_test, y_test=np.array(X_test), np.array(y_test)\n",
        "\n",
        "  X_test = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "  return X_train, y_train, X_test, y_test\n",
        "\n",
        "def mean_squared_error(y_true, y_pred):\n",
        "  mse = np.mean((y_true - y_pred) ** 2)\n",
        "  return mse\n",
        "\n",
        "def mean_absolute_error(y_true, y_pred):\n",
        "  mae = np.mean(np.abs(y_true - y_pred))\n",
        "  return mae\n",
        "\n",
        "def r_squared(y_true, y_pred):\n",
        "  y_mean = np.mean(y_true)\n",
        "  ss_total = np.sum((y_true - y_mean) ** 2)\n",
        "  ss_residual = np.sum((y_true - y_pred) ** 2)\n",
        "  r2 = 1 - (ss_residual / ss_total)\n",
        "  return r2\n",
        "\n",
        "X_train, y_train, X_test, y_test = load_dataset()\n",
        "clf = SVMRegression()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "print(\"MSE regression mean squared error:\", mean_squared_error(y_test, predictions))\n",
        "print(\"MAE regression mean absolute error:\", mean_absolute_error(y_test, predictions))\n",
        "print(\"R2 score:\", r_squared(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRs6Q7S0EFRH",
        "outputId": "14d318b6-368b-4856-fe10-61c5063f8740"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n",
            "MSE regression mean squared error: 0.018420207803019405\n",
            "MAE regression mean absolute error: 0.11903219712068351\n",
            "R2 score: 0.687568098988488\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yFd02zsFEGVO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}