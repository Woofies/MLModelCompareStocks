{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDnOcJuHgIkC",
        "outputId": "fab8e496-9be1-4aeb-92d1-fbda04012d38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n",
            "                 Open       High        Low      Close  Adj Close     Volume\n",
            "Date                                                                        \n",
            "2018-07-27  48.747501  48.797501  47.525002  47.744999  45.628719   96096000\n",
            "2018-07-30  47.974998  48.049999  47.267502  47.477501  45.373070   84118000\n",
            "2018-07-31  47.575001  48.035000  47.334999  47.572498  45.463852  157492000\n",
            "2018-08-01  49.782501  50.439999  49.327499  50.375000  48.142151  271742800\n",
            "2018-08-02  50.145000  52.095001  50.087502  51.847500  49.549374  249616000\n",
            "                  Open        High         Low       Close   Adj Close  \\\n",
            "Date                                                                     \n",
            "2023-07-20  195.089996  196.470001  192.500000  193.130005  193.130005   \n",
            "2023-07-21  194.100006  194.970001  191.229996  191.940002  191.940002   \n",
            "2023-07-24  193.410004  194.910004  192.250000  192.750000  192.750000   \n",
            "2023-07-25  193.330002  194.440002  192.919998  193.619995  193.619995   \n",
            "2023-07-26  193.669998  195.639999  193.322403  194.500000  194.500000   \n",
            "\n",
            "              Volume  \n",
            "Date                  \n",
            "2023-07-20  59581200  \n",
            "2023-07-21  71917800  \n",
            "2023-07-24  45377800  \n",
            "2023-07-25  37283200  \n",
            "2023-07-26  45981484  \n",
            "(1257, 6)\n",
            "\n",
            "(1005, 1)\n",
            "(252, 1)\n",
            "\n",
            "\n",
            "\n",
            "(905, 100)\n",
            "(905,)\n",
            "(152, 100)\n",
            "(152,)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Replace the stock symbol for respective ticker interested in comparing\n",
        "stock_symbol = 'AAPL' # AAPL AMZN NVDA CNRG TAN BTC AMD INTC\n",
        "df = yf.download(tickers=stock_symbol, period = '5y', interval = '1d') # Get data for the last 5 years w/ interval set to 1 day for all cases\n",
        "type(df)\n",
        "print(df.head())\n",
        "print(df.tail())\n",
        "print(df.shape)\n",
        "print('')\n",
        "\n",
        "# Train/Test\n",
        "data_training=pd.DataFrame(df['Close'][0:int(len(df)*0.80)])\n",
        "data_testing=pd.DataFrame(df['Close'][int(len(df)*0.80):int(len(df))])\n",
        "print(data_training.shape)\n",
        "print(data_testing.shape)\n",
        "print('')\n",
        "print('')\n",
        "print('')\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler=MinMaxScaler(feature_range=(0,1))\n",
        "\n",
        "data_training_array=scaler.fit_transform(data_training)\n",
        "data_training_array\n",
        "\n",
        "data_training_array.shape\n",
        "\n",
        "X_train=[]\n",
        "y_train=[]\n",
        "\n",
        "for i in range(100, data_training_array.shape[0]):\n",
        "    X_train.append(data_training_array[i-100:i])\n",
        "    y_train.append(data_training_array[i,0])\n",
        "X_train, y_train=np.array(X_train), np.array(y_train)\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "\n",
        "data_testing_array=scaler.fit_transform(data_testing)\n",
        "data_testing_array\n",
        "\n",
        "data_testing_array.shape\n",
        "\n",
        "X_test=[]\n",
        "y_test=[]\n",
        "\n",
        "for i in range(100, data_testing_array.shape[0]):\n",
        "    X_test.append(data_testing_array[i-100:i])\n",
        "    y_test.append(data_testing_array[i,0])\n",
        "X_test, y_test=np.array(X_test), np.array(y_test)\n",
        "\n",
        "X_test = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TS9SWRncUGbJ",
        "outputId": "2b760140-8da7-45fb-c636-4006ef08af16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(905, 700)\n",
            "(905,)\n",
            "(152, 700)\n",
            "(152,)\n"
          ]
        }
      ],
      "source": [
        "# Replace the stock symbols for respective tickers interested in comparing\n",
        "tickers = ['AAPL']  # You can add more tickers if needed\n",
        "columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
        "df = yf.download(tickers=tickers, period='5y', interval='1d', progress=False, auto_adjust=True, actions=False)\n",
        "df = df[columns]  # Select the desired columns from the DataFrame\n",
        "# Calculate daily percentage change (returns)\n",
        "df['Returns'] = df['Close'].pct_change()\n",
        "\n",
        "# Calculate the 5-day moving average\n",
        "df['MA_5'] = df['Close'].rolling(window=5).mean()\n",
        "\n",
        "# Select the desired features for training\n",
        "selected_features = ['Close', 'Open', 'High', 'Low', 'Volume', 'Returns', 'MA_5']\n",
        "data_training = pd.DataFrame(df[selected_features][0:int(len(df) * 0.80)])\n",
        "data_testing = pd.DataFrame(df[selected_features][int(len(df) * 0.80):int(len(df))])\n",
        "\n",
        "# Perform MinMax scaling\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "data_training_array = scaler.fit_transform(data_training)\n",
        "data_testing_array = scaler.transform(data_testing)\n",
        "\n",
        "# Create input sequences and target for training data\n",
        "X_train = []\n",
        "y_train = []\n",
        "for i in range(100, data_training_array.shape[0]):\n",
        "    X_train.append(data_training_array[i - 100:i])\n",
        "    y_train.append(data_training_array[i, 0])\n",
        "X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "\n",
        "# Reshape the input sequences to 2D\n",
        "X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "\n",
        "# Create input sequences and target for testing data\n",
        "X_test = []\n",
        "y_test = []\n",
        "for i in range(100, data_testing_array.shape[0]):\n",
        "    X_test.append(data_testing_array[i - 100:i])\n",
        "    y_test.append(data_testing_array[i, 0])\n",
        "X_test, y_test = np.array(X_test), np.array(y_test)\n",
        "\n",
        "# Reshape the input sequences to 2D\n",
        "X_test = X_test.reshape(X_test.shape[0], -1)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EBTxYRtiJpI"
      },
      "outputs": [],
      "source": [
        "def load_dataset():\n",
        "  # Replace the stock symbol for respective ticker interested in comparing\n",
        "  stock_symbol = 'AAPL' # AAPL AMZN NVDA CNRG TAN BTC AMD INTC\n",
        "  df = yf.download(tickers=stock_symbol, period = '5y', interval = '1d') # Get data for the last 5 years w/ interval set to 1 day for all cases\n",
        "  type(df)\n",
        "\n",
        "  # Train/Test\n",
        "  data_training=pd.DataFrame(df['Close'][0:int(len(df)*0.80)])\n",
        "  data_testing=pd.DataFrame(df['Close'][int(len(df)*0.80):int(len(df))])\n",
        "\n",
        "  scaler=MinMaxScaler(feature_range=(0,1))\n",
        "\n",
        "  data_training_array=scaler.fit_transform(data_training)\n",
        "  data_training_array\n",
        "  data_training_array.shape\n",
        "\n",
        "  X_train=[]\n",
        "  y_train=[]\n",
        "\n",
        "  for i in range(100, data_training_array.shape[0]):\n",
        "    X_train.append(data_training_array[i-100:i])\n",
        "    y_train.append(data_training_array[i, 0])\n",
        "  X_train, y_train=np.array(X_train), np.array(y_train)\n",
        "\n",
        "  X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "\n",
        "  data_testing_array=scaler.fit_transform(data_testing)\n",
        "  data_testing_array\n",
        "\n",
        "  data_testing_array.shape\n",
        "\n",
        "  X_test=[]\n",
        "  y_test=[]\n",
        "\n",
        "  for i in range(100, data_testing_array.shape[0]):\n",
        "    X_test.append(data_testing_array[i-100:i])\n",
        "    y_test.append(data_testing_array[i, 0])\n",
        "  X_test, y_test=np.array(X_test), np.array(y_test)\n",
        "\n",
        "  X_test = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "  return X_train, y_train, X_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nR3nOCTdp-eK",
        "outputId": "dd4f270e-c933-4007-8063-b93bc00d2017"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285397 sha256=8780778632d11eaa7d49d4fad2a1e8a40b48985205a145acb26b4b411bc07ef0\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ohw9wonpXLo"
      },
      "outputs": [],
      "source": [
        "class SVMRegression:\n",
        "\n",
        "    def __init__(self, learning_rate=0.001, lambda_param=0.01, n_iters=1000):\n",
        "        self.lr = learning_rate\n",
        "        self.lambda_param = lambda_param\n",
        "        self.n_iters = n_iters\n",
        "        self.w = None\n",
        "        self.b = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        # init weights\n",
        "        self.w = np.zeros(n_features)\n",
        "        self.b = 0\n",
        "\n",
        "        for _ in range(self.n_iters):\n",
        "            for idx, x_i in enumerate(X):\n",
        "                prediction = np.dot(x_i, self.w) - self.b\n",
        "                error = y[idx] - prediction\n",
        "\n",
        "                # Update weights and bias\n",
        "                self.w -= self.lr * (2 * self.lambda_param * self.w - np.dot(x_i, error))\n",
        "                self.b -= self.lr * (-2 * self.lambda_param * self.b + error)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.dot(X, self.w) - self.b\n",
        "\n",
        "# Testing\n",
        "if __name__ == \"__main__\":\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn import datasets\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    X, y = datasets.make_blobs(\n",
        "        n_samples=50, n_features=2, centers=2, cluster_std=1.05, random_state=40\n",
        "    )\n",
        "    y = np.where(y == 0, -1, 1)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=123\n",
        "    )\n",
        "\n",
        "    clf = SVMRegression()\n",
        "    clf.fit(X_train, y_train)\n",
        "    predictions = clf.predict(X_test)\n",
        "\n",
        "    def mean_squared_error(y_true, y_pred):\n",
        "        mse = np.mean((y_true - y_pred) ** 2)\n",
        "        return mse\n",
        "\n",
        "    def mean_absolute_error(y_true, y_pred):\n",
        "        mae = np.mean(np.abs(y_true - y_pred))\n",
        "        return mae\n",
        "\n",
        "    def accuracy(y_true, y_pred):\n",
        "        accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
        "        return accuracy\n",
        "\n",
        "    def r_squared(y_true, y_pred):\n",
        "        y_mean = np.mean(y_true)\n",
        "        ss_total = np.sum((y_true - y_mean) ** 2)\n",
        "        ss_residual = np.sum((y_true - y_pred) ** 2)\n",
        "        r2 = 1 - (ss_residual / ss_total)\n",
        "        return r2\n",
        "\n",
        "    print(\"MSE regression mean squared error:\", mean_squared_error(y_test, predictions))\n",
        "    print(\"MAE regression mean absolute error:\", mean_absolute_error(y_test, predictions))\n",
        "    print(\"MAE regression accuracy:\", 1 - accuracy(y_test, predictions))\n",
        "    print(\"R2 score:\", r_squared(y_test, predictions))\n",
        "\n",
        "    def visualize_svm():\n",
        "        fig = plt.figure()\n",
        "        ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
        "        ax.scatter(X[:, 0], X[:, 1], y, marker=\"o\", c='blue')\n",
        "\n",
        "        x0_1 = np.amin(X[:, 0])\n",
        "        x0_2 = np.amax(X[:, 0])\n",
        "\n",
        "        x1_1 = clf.predict(np.array([x0_1, x0_1]))\n",
        "        x1_2 = clf.predict(np.array([x0_2, x0_2]))\n",
        "\n",
        "        ax.plot([x0_1, x0_2], [x1_1, x1_2], [0, 0], \"r--\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "    visualize_svm()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jz3r4KD4CVAk",
        "outputId": "5bff754e-9e11-4282-a550-359a9328f0f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n",
            "MSE regression mean squared error: 0.0148403488956415\n",
            "MAE regression mean absolute error: 0.11011352434540837\n",
            "MAE regression accuracy: 1.0\n",
            "R2 score: 0.8083116710006496\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "class SVMRegression:\n",
        "\n",
        "    def __init__(self, learning_rate=0.001, lambda_param=0.01, n_iters=1000):\n",
        "        self.lr = learning_rate\n",
        "        self.lambda_param = lambda_param\n",
        "        self.n_iters = n_iters\n",
        "        self.w = None\n",
        "        self.b = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        # init weights\n",
        "        self.w = np.zeros(n_features)\n",
        "        self.b = 0\n",
        "\n",
        "        for _ in range(self.n_iters):\n",
        "            for idx, x_i in enumerate(X):\n",
        "                prediction = np.dot(x_i, self.w) - self.b\n",
        "                error = y[idx] - prediction\n",
        "\n",
        "                # Update weights and bias\n",
        "                self.w -= self.lr * (2 * self.lambda_param * self.w - np.dot(x_i, error))\n",
        "                self.b -= self.lr * (-2 * self.lambda_param * self.b + error)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.dot(X, self.w) - self.b\n",
        "\n",
        "def load_dataset():\n",
        "  # Replace the stock symbol for respective ticker interested in comparing\n",
        "  stock_symbol = 'AAPL' # AAPL AMZN NVDA CNRG TAN BTC AMD INTC\n",
        "  df = yf.download(tickers=stock_symbol, period = '5y', interval = '1d') # Get data for the last 5 years w/ interval set to 1 day for all cases\n",
        "  type(df)\n",
        "\n",
        "  # Train/Test\n",
        "  data_training=pd.DataFrame(df['Close'][0:int(len(df)*0.80)])\n",
        "  data_testing=pd.DataFrame(df['Close'][int(len(df)*0.80):int(len(df))])\n",
        "\n",
        "  scaler=MinMaxScaler(feature_range=(0,1))\n",
        "\n",
        "  data_training_array=scaler.fit_transform(data_training)\n",
        "  data_training_array\n",
        "  data_training_array.shape\n",
        "\n",
        "  X_train=[]\n",
        "  y_train=[]\n",
        "\n",
        "  for i in range(100, data_training_array.shape[0]):\n",
        "    X_train.append(data_training_array[i-100:i])\n",
        "    y_train.append(data_training_array[i, 0])\n",
        "  X_train, y_train=np.array(X_train), np.array(y_train)\n",
        "\n",
        "  X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "\n",
        "  data_testing_array=scaler.fit_transform(data_testing)\n",
        "  data_testing_array\n",
        "\n",
        "  data_testing_array.shape\n",
        "\n",
        "  X_test=[]\n",
        "  y_test=[]\n",
        "\n",
        "  for i in range(100, data_testing_array.shape[0]):\n",
        "    X_test.append(data_testing_array[i-100:i])\n",
        "    y_test.append(data_testing_array[i, 0])\n",
        "  X_test, y_test=np.array(X_test), np.array(y_test)\n",
        "\n",
        "  X_test = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "  return X_train, y_train, X_test, y_test\n",
        "\n",
        "def mean_squared_error(y_true, y_pred):\n",
        "  mse = np.mean((y_true - y_pred) ** 2)\n",
        "  return mse\n",
        "\n",
        "def mean_absolute_error(y_true, y_pred):\n",
        "  mae = np.mean(np.abs(y_true - y_pred))\n",
        "  return mae\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
        "  return accuracy\n",
        "\n",
        "def r_squared(y_true, y_pred):\n",
        "  y_mean = np.mean(y_true)\n",
        "  ss_total = np.sum((y_true - y_mean) ** 2)\n",
        "  ss_residual = np.sum((y_true - y_pred) ** 2)\n",
        "  r2 = 1 - (ss_residual / ss_total)\n",
        "  return r2\n",
        "\n",
        "def visualize_svm():\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired, marker='o')\n",
        "\n",
        "    # Plot the decision boundary\n",
        "    ax = plt.gca()\n",
        "    xlim = ax.get_xlim()\n",
        "    ylim = ax.get_ylim()\n",
        "\n",
        "    # Create grid to evaluate model\n",
        "    xx = np.linspace(xlim[0], xlim[1], 30)\n",
        "    yy = np.linspace(ylim[0], ylim[1], 30)\n",
        "    YY, XX = np.meshgrid(yy, xx)\n",
        "    xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
        "    Z = clf.predict(xy).reshape(XX.shape)\n",
        "\n",
        "    # Plot decision boundary\n",
        "    ax.contourf(XX, YY, Z, colors=['b', 'r'], levels=[-1, 0, 1], alpha=0.5)\n",
        "\n",
        "    # Plot support vectors\n",
        "    ax.scatter(clf.w[0], clf.w[1], s=100, marker='o', c='g', label='Support Vectors')\n",
        "\n",
        "    ax.set_xlabel('Feature 1')\n",
        "    ax.set_ylabel('Feature 2')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "X_train, y_train, X_test, y_test = load_dataset()\n",
        "clf = SVMRegression()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "print(\"MSE regression mean squared error:\", mean_squared_error(y_test, predictions))\n",
        "print(\"MAE regression mean absolute error:\", mean_absolute_error(y_test, predictions))\n",
        "print(\"MAE regression accuracy:\", 1 - accuracy(y_test, predictions))\n",
        "print(\"R2 score:\", r_squared(y_test, predictions))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}